{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This script is used to generate five subfiles according to the original LAVA. For each file,\n",
    "we added two additional columns (used for the following classification tasks) by\n",
    "transformation from the existed columns, see details in https://docs.google.com/document/d/1VfcjkDbBPYZnMjGG4voIvMYs5dLDiAya-d_8TiJ6CWU/edit\n",
    "\n",
    "\n",
    "Usage: run the whole notebook, the subfiles will be saved to ./data/lava directory, also can get a sense of data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lava_path = \"./data/lava/all_verbs.csv\"\n",
    "alternation = pd.read_csv(lava_path, index_col='verb', dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inch = alternation.loc[:, 'inch':'non_inch']\n",
    "sl = alternation.loc[:, 'sl':'sl_nowith']\n",
    "there = alternation.loc[:, 'there':'non_there']\n",
    "dat = alternation.loc[:, 'dat_both':'dat_do']\n",
    "refl = alternation.loc[:, 'refl_op':'refl_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inchoative  causative\n",
       "x           x            299\n",
       "0           x             93\n",
       "1           1             73\n",
       "0           1             51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['inchoative', 'causative'])\n",
    "inch = pd.concat([inch, new_add])\n",
    "inch['inchoative'] = inch['inch']\n",
    "inch.loc[inch['non_inch']!='x', 'causative'] = '1'\n",
    "inch.loc[inch['non_inch'] =='x', 'causative'] = 'x'\n",
    "\n",
    "new_inch = inch[['inchoative', 'causative']]\n",
    "# new_inch.to_csv('./data/lava/inch.csv', index_label='verb')\n",
    "new_inch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preposition  2object\n",
       "0            0          344\n",
       "x            0           74\n",
       "1            1           41\n",
       "0            1           33\n",
       "1            0           24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['preposition', '2object'])\n",
    "dat = pd.concat([dat, new_add])\n",
    "dat['preposition'] = dat['dat_both']\n",
    "dat.loc[(dat['dat_both']==\"0\") & (dat['dative_to']=='x'), 'preposition'] = 'x'\n",
    "dat.loc[(dat['dat_both']==\"0\") & (dat['dative_to']=='1'), 'preposition'] = \"1\"\n",
    "dat['2object'] = dat['dat_do']\n",
    "dat.loc[(dat['dat_both']==\"1\"), '2object'] = \"1\"\n",
    "new_dat = dat[['preposition', '2object']]\n",
    "# new_dat.to_csv('./data/lava/dative.csv', index_label='verb')\n",
    "new_dat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "with  locative\n",
       "0     0           185\n",
       "x     x           173\n",
       "1     0            72\n",
       "0     1            57\n",
       "1     1            29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['with', 'locative'])\n",
    "sl = pd.concat([sl, new_add])\n",
    "sl['with'] = sl['sl_noloc']\n",
    "sl['locative'] = sl['sl_nowith']\n",
    "sl.loc[sl['sl']=='1', 'with'] = '1'\n",
    "sl.loc[sl['sl']=='1', 'locative'] = '1'\n",
    "new_sl = sl[['with', 'locative']]\n",
    "# new_sl.to_csv('./data/lava/sl.csv', index_label='verb')\n",
    "new_sl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There  No-There\n",
       "x      x           274\n",
       "0      1            99\n",
       "       x            93\n",
       "1      1            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['There', 'No-There'])\n",
    "there = pd.concat([there, new_add])\n",
    "there['No-There'] = there['non_there']\n",
    "there['There'] = there['there']\n",
    "there.loc[(there['non_there']=='x') & (there['there']!='x'), 'There'] = \"0\"\n",
    "there.loc[there['there'] == '1', 'No-There'] = \"1\"\n",
    "new_there = there[['There', 'No-There']]\n",
    "# new_there.to_csv('./data/lava/there.csv', index_label='verb')\n",
    "new_there.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Refl  Non-Refl\n",
       "0     0           419\n",
       "1     0            84\n",
       "x     1            11\n",
       "      x             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#still not sure whether need to put the refl-op[1,0] in the refl class\n",
    "new_add = pd.DataFrame(columns=['Refl', 'Non-Refl'])\n",
    "refl = pd.concat([refl, new_add])\n",
    "refl['Refl'] = refl['refl_only']\n",
    "refl['Non-Refl'] = refl['refl_op']\n",
    "refl.loc[(refl['refl_op']==\"1\")&(refl['refl_only']==\"1\"), 'Refl'] = 'x'\n",
    "refl.loc[(refl['refl_op']==\"1\")&(refl['refl_only']==\"1\"), 'Non-Refl'] = 'x'\n",
    "refl.loc[(refl['refl_op']==\"1\")&(refl['refl_only']==\"0\"), 'Refl'] = 'x'\n",
    "new_refl = refl[['Refl', 'Non-Refl']]\n",
    "# new_refl.to_csv('./data/lava/refl.csv', index_label='verb')\n",
    "new_refl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all subframes and save in one big frame\n",
    "verb_frames = pd.concat((new_inch, new_dat, new_sl, new_there, new_refl), axis=1)\n",
    "verb_frames.to_csv('./data/lava/verb_frames.csv', index_label='verb')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e494e532438ff838811626b00e7875b31c54814775bb1ff657520b2b9ee00627"
  },
  "kernelspec": {
   "display_name": "PyCharm (ling-575-analyzing-nn-group)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
