{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This script is used to generate five subfiles according to the original LAVA. For each file,\n",
    "we added two additional columns (used for the following classification tasks) by\n",
    "transformation from the existed columns, see details in https://docs.google.com/document/d/1VfcjkDbBPYZnMjGG4voIvMYs5dLDiAya-d_8TiJ6CWU/edit\n",
    "\n",
    "\n",
    "Usage: run the whole notebook, the subfiles will be saved to ./data/lava directory, also can get a sense of data distribution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lava_path = \"./data/lava/all_verbs.csv\"\n",
    "alternation = pd.read_csv(lava_path, index_col='verb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "inch = alternation.loc[:, 'inch':'non_inch']\n",
    "sl = alternation.loc[:, 'sl':'sl_nowith']\n",
    "there = alternation.loc[:, 'there':'non_there']\n",
    "dat = alternation.loc[:, 'dat_both':'dat_do']\n",
    "refl = alternation.loc[:, 'refl_op':'refl_only']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "inch  non_inch  inchoative  causative\nx     x         x           x            299\n0     x         0           x             93\n1     0         1           1             73\n0     1         0           1             51\ndtype: int64"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['inchoative', 'causative'])\n",
    "inch = pd.concat([inch, new_add])\n",
    "inch['inchoative'] = inch['inch']\n",
    "inch.loc[inch['non_inch']!='x', 'causative'] = '1'\n",
    "inch.loc[inch['non_inch'] =='x', 'causative'] = 'x'\n",
    "inch.to_csv('./data/lava/inch.csv')\n",
    "inch.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "dat_both  dative_to  dat_do  preposition  2object\n0.0       0          0.0     0.0          0.0        344\n          x          0.0     x            0.0         74\n1.0       0          0.0     1.0          1.0         41\n0.0       0          1.0     0.0          1.0         33\n          1          0.0     1.0          0.0         24\ndtype: int64"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['preposition', '2object'])\n",
    "dat = pd.concat([dat, new_add])\n",
    "dat['preposition'] = dat['dat_both']\n",
    "dat.loc[(dat['dat_both']==0) & (dat['dative_to']=='x'), 'preposition'] = 'x'\n",
    "dat.loc[(dat['dat_both']==0) & (dat['dative_to']=='1'), 'preposition'] = 1\n",
    "dat['2object'] = dat['dat_do']\n",
    "dat.loc[(dat['dat_both']==1), '2object'] = 1\n",
    "dat.to_csv('./data/lava/dative.csv')\n",
    "dat.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "sl  sl_noloc  sl_nowith  with  locative\n0   0         0          0     0           185\nx   x         x          x     x           173\n0   1         0          1     0            72\n    0         1          0     1            57\n1   0         0          1     1            29\ndtype: int64"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['with', 'locative'])\n",
    "sl = pd.concat([sl, new_add])\n",
    "sl['with'] = sl['sl_noloc']\n",
    "sl['locative'] = sl['sl_nowith']\n",
    "sl.loc[sl['sl']=='1', 'with'] = '1'\n",
    "sl.loc[sl['sl']=='1', 'locative'] = '1'\n",
    "sl.to_csv('./data/lava/sl.csv')\n",
    "sl.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "there  non_there  There  No-There\nx      x          x      x           274\n0      1          0      1            99\n       x          0      x            93\n1      0          1      1            50\ndtype: int64"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_add = pd.DataFrame(columns=['There', 'No-There'])\n",
    "there = pd.concat([there, new_add])\n",
    "there['No-There'] = there['non_there']\n",
    "there['There'] = there['there']\n",
    "there.loc[(there['non_there']=='x') & (there['there']!='x'), 'There'] = 0\n",
    "there.loc[there['there'] == '1', 'No-There'] = 1\n",
    "there.to_csv('./data/lava/there.csv')\n",
    "there.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "refl_op  refl_only  Refl  Non-Refl\n0.0      0.0        0.0   0.0         419\n         1.0        1.0   0.0          84\n1.0      0.0        x     1.0          11\n         1.0        x     x             2\ndtype: int64"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#still not sure whether need to put the refl-op[1,0] in the refl class\n",
    "new_add = pd.DataFrame(columns=['Refl', 'Non-Refl'])\n",
    "refl = pd.concat([refl, new_add])\n",
    "refl['Refl'] = refl['refl_only']\n",
    "refl['Non-Refl'] = refl['refl_op']\n",
    "refl.loc[(refl['refl_op']==1)&(refl['refl_only']==1), 'Refl'] = 'x'\n",
    "refl.loc[(refl['refl_op']==1)&(refl['refl_only']==1), 'Non-Refl'] = 'x'\n",
    "refl.loc[(refl['refl_op']==1)&(refl['refl_only']==0), 'Refl'] = 'x'\n",
    "refl.to_csv('./data/lava/refl.csv')\n",
    "refl.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ling-575-analyzing-nn-group)",
   "language": "python",
   "name": "pycharm-406f1027"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}